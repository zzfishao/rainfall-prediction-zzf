{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b691890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor([[[-0.0338,  0.1641,  0.2356],\n",
      "         [-0.1276,  0.1819,  0.3085],\n",
      "         [-0.0627,  0.1581,  0.1736]],\n",
      "\n",
      "        [[-0.0144,  0.1480, -0.0043],\n",
      "         [ 0.0130,  0.1638,  0.0774],\n",
      "         [ 0.0719,  0.1236,  0.0584]]], grad_fn=<TransposeBackward0>)\n",
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 torch.Size([20, 3])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n",
      "weight_hr_l0 torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义常量\n",
    "bs, T, i_size, h_size = 2, 3, 4, 5 #batch_size  Time  input_size hidden_size\n",
    "proj_size = 3 #投影大小\n",
    "input = torch.randn(bs, T, i_size)\n",
    "print(input.shape)\n",
    "c0 = torch.randn(bs, h_size) # 初始值 不参与训练\n",
    "h0 = torch.randn(bs, proj_size) # 初始值 不参与训练\n",
    "\n",
    "# 调用官方API\n",
    "lstm_layer = nn.LSTM(i_size, h_size, batch_first=True, proj_size=proj_size)\n",
    "output, (h_n, c_n) = lstm_layer(input, (h0.unsqueeze(0), c0.unsqueeze(0)))\n",
    "print(output)\n",
    "\n",
    "for k, v in lstm_layer.named_parameters():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d1e0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.0233e-01, -1.6884e-01, -8.2945e-02],\n",
      "         [ 7.6853e-03,  8.5598e-02, -6.2300e-02],\n",
      "         [ 1.3547e-02, -2.7407e-03, -1.4973e-04]],\n",
      "\n",
      "        [[-1.3269e-01, -9.3741e-02, -8.3748e-02],\n",
      "         [-2.5617e-02,  1.6450e-02, -2.7930e-02],\n",
      "         [ 4.7940e-02,  9.6475e-02, -5.1577e-02]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "# 自己写一个LSTM\n",
    "def lstm_forward(input, initial_states, w_ih, w_hh, b_ih, b_hh, w_hr=None):\n",
    "    h0, c0 = initial_states # 初始状态\n",
    "    bs, T, i_size = input.shape\n",
    "    h_size = w_ih.shape[0] # 20\n",
    "    h_size = h_size // 4 # 分为4份\n",
    "    \n",
    "    prev_h = h0 # 不停更新h0 c0\n",
    "    prev_c = c0 \n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs, 1, 1) # bs * 4*h_size * i_size\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs, 1, 1) # bs * 4*h_size * h_size\n",
    "    \n",
    "    if w_hr is not None:\n",
    "        p_size, _ = w_hr.shape\n",
    "        output_size = p_size\n",
    "        batch_w_hr = w_hr.unsqueeze(0).tile(bs, 1, 1)\n",
    "    else:\n",
    "        output_size = h_size\n",
    "    output = torch.zeros(bs, T, output_size) # 输出序列\n",
    "    \n",
    "    for t in range(T):\n",
    "        x = input[:, t, :] # 当前时刻的输入向量 bs * i_size\n",
    "        w_times_x = torch.bmm(batch_w_ih, x.unsqueeze(-1)) # bs * 4*h_size * 1\n",
    "        w_times_x = w_times_x.squeeze(-1) # bs * 4*h_size\n",
    "        \n",
    "        w_times_h = torch.bmm(batch_w_hh, prev_h.unsqueeze(-1)) # bs * 4*h_size * 1\n",
    "        w_times_h = w_times_h.squeeze(-1) # bs * 4*h_size\n",
    "        \n",
    "        # 分别各取四分之一\n",
    "        i_t = torch.sigmoid(w_times_x[:, :h_size] + w_times_h[:, :h_size] + b_ih[:h_size] + b_hh[:h_size]) # 取前四分之一\n",
    "        f_t = torch.sigmoid(w_times_x[:, h_size: 2*h_size] + w_times_h[:, h_size: 2*h_size] + b_ih[h_size: 2*h_size] + b_hh[h_size: 2*h_size])\n",
    "        g_t = torch.tanh(w_times_x[:, 2*h_size: 3*h_size] + w_times_h[:, 2*h_size: 3*h_size] + b_ih[2*h_size: 3*h_size] + b_hh[2*h_size: 3*h_size])\n",
    "        o_t = torch.sigmoid(w_times_x[:, 3*h_size:] + w_times_h[:, 3*h_size:] + b_ih[3*h_size:] + b_hh[3*h_size:])\n",
    "        prev_c = f_t * prev_c + i_t * g_t\n",
    "        prev_h = o_t * torch.tanh(prev_c)\n",
    "        \n",
    "        if w_hr is not None:  # 进行projection 对维度进行压缩\n",
    "            prev_h = torch.bmm(batch_w_hr, prev_h.unsqueeze(-1))\n",
    "            prev_h = prev_h.squeeze(-1)\n",
    "        \n",
    "        output[:, t, :] = prev_h\n",
    "        \n",
    "    return output, (prev_h, prev_c)\n",
    " \n",
    "    \n",
    "    \n",
    "output_custom, (h_0_custom, c_0_custom) = lstm_forward(input, (h0, c0), lstm_layer.weight_ih_l0, lstm_layer.weight_hh_l0,\\\n",
    "                                                       lstm_layer.bias_ih_l0, lstm_layer.bias_hh_l0, lstm_layer.weight_hr_l0)\n",
    "\n",
    "print(output_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f0a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
